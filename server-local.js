/**
 * ENERLUX CALL CENTER IA - SERVIDOR LOCAL (VB-CABLE + ZADARMA)
 * Sistema de llamadas con IA usando VB-CABLE para audio local
 */

import fetch from 'node-fetch';
import fs from 'fs';
import path from 'path';
import { exec } from 'child_process';
import { fileURLToPath } from 'url';
import dotenv from 'dotenv';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

dotenv.config();

// Estado del sistema
let conversacionActiva = false;
let historialConversacion = [];

// ConfiguraciÃ³n
const CONFIG = {
  openai_key: process.env.OPENAI_API_KEY,
  elevenlabs_key: process.env.ELEVENLABS_API_KEY,
  elevenlabs_voice_id: '21m00Tcm4TlvDq8ikWAM', // Rachel - voz natural
  audio_input: 'CABLE Output (VB-Audio Virtual Cable)', // MicrÃ³fono virtual
  audio_output: 'CABLE Input (VB-Audio Virtual Cable)', // Altavoz virtual
  idioma: 'es'
};

console.log('ğŸ“ ENERLUX CALL CENTER IA - Servidor Local');
console.log('==========================================');
console.log(`ğŸ”‘ OpenAI: ${CONFIG.openai_key ? 'âœ… Configurado' : 'âŒ Falta'}`);
console.log(`ğŸ”‘ ElevenLabs: ${CONFIG.elevenlabs_key ? 'âœ… Configurado' : 'âŒ Falta'}`);
console.log(`ğŸ§ Audio Input: ${CONFIG.audio_input}`);
console.log(`ğŸ§ Audio Output: ${CONFIG.audio_output}`);
console.log('');

// ========================================
// FUNCIONES DE AUDIO
// ========================================

/**
 * Grabar audio del micrÃ³fono virtual (CABLE Output)
 */
async function grabarAudio(duracionMs = 5000) {
  return new Promise((resolve, reject) => {
    const outputFile = path.join(__dirname, 'temp', 'input.wav');
    
    // Crear carpeta temp si no existe
    if (!fs.existsSync(path.join(__dirname, 'temp'))) {
      fs.mkdirSync(path.join(__dirname, 'temp'), { recursive: true });
    }

    const cmd = `ffmpeg -y -f dshow -i audio="${CONFIG.audio_input}" -t ${duracionMs/1000} -acodec pcm_s16le -ar 16000 -ac 1 "${outputFile}"`;
    
    console.log(`ğŸ¤ Grabando audio por ${duracionMs/1000}s...`);
    
    exec(cmd, (error, stdout, stderr) => {
      if (error && !fs.existsSync(outputFile)) {
        const cmd2 = `ffmpeg -y -f wasapi -i audio_output_default -t ${duracionMs/1000} -acodec pcm_s16le -ar 16000 -ac 1 "${outputFile}"`;
        exec(cmd2, (err2) => {
          if (err2) {
            console.log('âš ï¸ Error grabando, usando simulaciÃ³n');
            resolve(null);
          } else {
            resolve(outputFile);
          }
        });
      } else {
        resolve(outputFile);
      }
    });
  });
}

/**
 * Reproducir audio por el altavoz virtual (CABLE Input)
 */
async function reproducirAudio(archivoAudio) {
  return new Promise((resolve, reject) => {
    const cmd = `ffplay -autoexit -nodisp "${archivoAudio}"`;
    
    console.log(`ğŸ”Š Reproduciendo audio...`);
    
    exec(cmd, (error) => {
      if (error) {
        const psCmd = `powershell -c (New-Object Media.SoundPlayer "${archivoAudio}").PlaySync()`;
        exec(psCmd, () => resolve());
      } else {
        resolve();
      }
    });
  });
}

// ========================================
// FUNCIONES DE IA
// ========================================

/**
 * Transcribir audio con OpenAI Whisper
 */
async function transcribirAudio(archivoAudio) {
  if (!archivoAudio || !fs.existsSync(archivoAudio)) {
    return null;
  }

  console.log('ğŸ“ Transcribiendo con Whisper...');
  
  const audioBuffer = fs.readFileSync(archivoAudio);
  const FormData = (await import('form-data')).default;
  const form = new FormData();
  form.append('file', audioBuffer, 'audio.wav');
  form.append('model', 'whisper-1');
  form.append('language', CONFIG.idioma);

  const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${CONFIG.openai_key}`,
      ...form.getHeaders()
    },
    body: form
  });

  if (!response.ok) {
    console.log('âš ï¸ Error en Whisper');
    return null;
  }

  const data = await response.json();
  console.log(`ğŸ“ TranscripciÃ³n: "${data.text}"`);
  return data.text;
}

/**
 * Generar respuesta con GPT-4
 */
async function generarRespuesta(mensajeUsuario) {
  historialConversacion.push({
    role: 'user',
    content: mensajeUsuario
  });

  console.log('ğŸ¤– Generando respuesta con GPT-4...');

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${CONFIG.openai_key}`
    },
    body: JSON.stringify({
      model: 'gpt-4o',
      messages: [
        {
          role: 'system',
          content: `Eres un agente telefÃ³nico de Enerlux, empresa de cambio de compaÃ±Ã­a elÃ©ctrica en EspaÃ±a.

Tu objetivo es convencer al cliente de cambiarse a Enerlux para ahorrar en su factura de luz.

REGLAS:
- SÃ© amable pero persuasivo
- Responde de forma BREVE (mÃ¡ximo 2 frases cortas)
- Si el cliente estÃ¡ interesado, pide su nÃºmero de cuenta bancaria IBAN
- Si el cliente no estÃ¡ interesado, pregunta si conoce a alguien que pueda estarlo
- Si el cliente tiene preguntas, respÃ³ndelas claramente

INFORMACIÃ“N DE ENERLUX:
- Ahorro garantizado del 15-20% en factura mensual
- Sin permanencia
- Cambio gratis
- 100% energÃ­a renovable
- Precios congelados por 12 meses

Responde SIEMPRE en espaÃ±ol, de forma natural y conversacional.`
        },
        ...historialConversacion.slice(-10)
      ],
      max_tokens: 100
    })
  });

  const data = await response.json();
  
  if (!response.ok || !data.choices || !data.choices[0]) {
    console.log('âŒ Error OpenAI:', JSON.stringify(data));
    return "Disculpe, podrÃ­a repetir eso por favor?";
  }
  
  const respuesta = data.choices[0].message.content;

  historialConversacion.push({
    role: 'assistant',
    content: respuesta
  });

  console.log(`ğŸ¤– Respuesta: "${respuesta}"`);
  return respuesta;
}

/**
 * Convertir texto a voz con ElevenLabs
 */
async function textoAVoz(texto) {
  console.log('ğŸ”Š Convirtiendo a voz con ElevenLabs...');

  try {
    const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${CONFIG.elevenlabs_voice_id}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'xi-api-key': CONFIG.elevenlabs_key
      },
      body: JSON.stringify({
        text: texto,
        model_id: 'eleven_multilingual_v2',
        voice_settings: {
          stability: 0.5,
          similarity_boost: 0.75,
          style: 0.5,
          use_speaker_boost: true
        }
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.log('âš ï¸ Error ElevenLabs:', response.status, errorText.substring(0, 200));
      return null;
    }

  const audioBuffer = await response.buffer();
  const outputFile = path.join(__dirname, 'temp', 'output.mp3');
  
  if (!fs.existsSync(path.join(__dirname, 'temp'))) {
    fs.mkdirSync(path.join(__dirname, 'temp'), { recursive: true });
  }
  
  fs.writeFileSync(outputFile, audioBuffer);
  
  console.log(`âœ… Audio generado: ${outputFile}`);
  return outputFile;
  } catch (error) {
    console.log('âš ï¸ Error en ElevenLabs:', error.message);
    return null;
  }
}

// ========================================
// MODO INTERACTIVO (para pruebas)
// ========================================

async function modoInteractivo() {
  const readline = await import('readline');
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout
  });

  console.log('');
  console.log('ğŸ® â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('ğŸ® MODO INTERACTIVO (pruebas sin audio)');
  console.log('ğŸ® Escribe lo que dirÃ­a el cliente');
  console.log('ğŸ® Escribe "salir" para terminar');
  console.log('ğŸ® â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('');

  const saludo = "Hola, le llamo de Enerlux. Â¿PodrÃ­a hablar un momento sobre su factura de luz?";
  console.log(`ğŸ—£ï¸ IA: "${saludo}"`);
  
  const audioSaludo = await textoAVoz(saludo);
  if (audioSaludo) {
    console.log(`ğŸ”Š Audio guardado en: ${audioSaludo}`);
  }

  const preguntar = () => {
    rl.question('ğŸ‘¤ Cliente: ', async (input) => {
      if (input.toLowerCase() === 'salir') {
        console.log('ğŸ‘‹ Â¡Hasta luego!');
        rl.close();
        return;
      }

      const respuesta = await generarRespuesta(input);
      console.log(`ğŸ—£ï¸ IA: "${respuesta}"`);

      const audio = await textoAVoz(respuesta);
      if (audio) {
        console.log(`ğŸ”Š Audio guardado en: ${audio}`);
      }

      preguntar();
    });
  };

  preguntar();
}

// ========================================
// INICIAR
// ========================================

const args = process.argv.slice(2);
if (args.includes('--interactivo') || args.includes('-i')) {
  modoInteractivo();
} else if (args.includes('--llamar') || args.includes('-l')) {
  console.log('ğŸ“ Modo llamada con audio real');
  console.log('âš ï¸ AsegÃºrate de que Zadarma estÃ¡ conectado');
  modoInteractivo();
} else {
  console.log('ğŸ“ USO:');
  console.log('');
  console.log('  node server-local.js --interactivo  â†’ Prueba escribiendo');
  console.log('  node server-local.js --llamar       â†’ Con audio real (VB-CABLE)');
  console.log('');
  modoInteractivo();
}