/**
 * ENERLUX CALL CENTER IA - SERVIDOR LOCAL (VB-CABLE + ZADARMA)
 * Sistema de llamadas con IA usando VB-CABLE para audio local
 */

const fetch = require('node-fetch');
const fs = require('fs');
const path = require('path');
const { exec } = require('child_process');
const wav = require('wav');
require('dotenv').config();

// Estado del sistema
let conversacionActiva = false;
let historialConversacion = [];

// ConfiguraciÃ³n
const CONFIG = {
  openai_key: process.env.OPENAI_API_KEY,
  elevenlabs_key: process.env.ELEVENLABS_API_KEY,
  elevenlabs_voice_id: '21m00Tcm4TlvDq8ikWAM', // Rachel - voz natural
  audio_input: 'CABLE Output (VB-Audio Virtual Cable)', // MicrÃ³fono virtual
  audio_output: 'CABLE Input (VB-Audio Virtual Cable)', // Altavoz virtual
  idioma: 'es'
};

console.log('ğŸ“ ENERLUX CALL CENTER IA - Servidor Local');
console.log('==========================================');
console.log(`ğŸ”‘ OpenAI: ${CONFIG.openai_key ? 'âœ… Configurado' : 'âŒ Falta'}`);
console.log(`ğŸ”‘ ElevenLabs: ${CONFIG.elevenlabs_key ? 'âœ… Configurado' : 'âŒ Falta'}`);
console.log(`ğŸ§ Audio Input: ${CONFIG.audio_input}`);
console.log(`ğŸ§ Audio Output: ${CONFIG.audio_output}`);
console.log('');

// ========================================
// FUNCIONES DE AUDIO
// ========================================

/**
 * Grabar audio del micrÃ³fono virtual (CABLE Output)
 * El softphone Zadarma envÃ­a el audio del cliente aquÃ­
 */
async function grabarAudio(duracionMs = 5000) {
  return new Promise((resolve, reject) => {
    const outputFile = path.join(__dirname, 'temp', 'input.wav');
    
    // Crear carpeta temp si no existe
    if (!fs.existsSync(path.join(__dirname, 'temp'))) {
      fs.mkdirSync(path.join(__dirname, 'temp'), { recursive: true });
    }

    // Usar ffmpeg para grabar del dispositivo VB-CABLE
    // En Windows, necesitamos usar dshow o wasapi
    const cmd = `ffmpeg -y -f dshow -i audio="${CONFIG.audio_input}" -t ${duracionMs/1000} -acodec pcm_s16le -ar 16000 -ac 1 "${outputFile}"`;
    
    console.log(`ğŸ¤ Grabando audio por ${duracionMs/1000}s...`);
    
    exec(cmd, (error, stdout, stderr) => {
      if (error && !fs.existsSync(outputFile)) {
        // Intentar alternativo con wasapi
        const cmd2 = `ffmpeg -y -f wasapi -i audio_output_default -t ${duracionMs/1000} -acodec pcm_s16le -ar 16000 -ac 1 "${outputFile}"`;
        exec(cmd2, (err2) => {
          if (err2) {
            console.log('âš ï¸ Error grabando, usando simulaciÃ³n');
            resolve(null);
          } else {
            resolve(outputFile);
          }
        });
      } else {
        resolve(outputFile);
      }
    });
  });
}

/**
 * Reproducir audio por el altavoz virtual (CABLE Input)
 * El softphone Zadarma recibe este audio y lo envÃ­a al cliente
 */
async function reproducirAudio(archivoAudio) {
  return new Promise((resolve, reject) => {
    // Usar ffplay o Windows Media Player
    const cmd = `ffplay -autoexit -nodisp "${archivoAudio}"`;
    
    console.log(`ğŸ”Š Reproduciendo audio...`);
    
    exec(cmd, (error) => {
      if (error) {
        // Alternativo: usar PowerShell
        const psCmd = `powershell -c (New-Object Media.SoundPlayer "${archivoAudio}").PlaySync()`;
        exec(psCmd, () => resolve());
      } else {
        resolve();
      }
    });
  });
}

// ========================================
// FUNCIONES DE IA
// ========================================

/**
 * Transcribir audio con OpenAI Whisper
 */
async function transcribirAudio(archivoAudio) {
  if (!archivoAudio || !fs.existsSync(archivoAudio)) {
    return null;
  }

  console.log('ğŸ“ Transcribiendo con Whisper...');
  
  const audioBuffer = fs.readFileSync(archivoAudio);
  const formData = new FormData();
  formData.append('file', new Blob([audioBuffer]), 'audio.wav');
  formData.append('model', 'whisper-1');
  formData.append('language', CONFIG.idioma);

  const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${CONFIG.openai_key}`
    },
    body: formData
  });

  if (!response.ok) {
    console.log('âš ï¸ Error en Whisper, usando texto de prueba');
    return "Hola, me interesa cambiar de compaÃ±Ã­a elÃ©ctrica";
  }

  const data = await response.json();
  console.log(`ğŸ“ TranscripciÃ³n: "${data.text}"`);
  return data.text;
}

/**
 * Generar respuesta con GPT-4
 */
async function generarRespuesta(mensajeUsuario) {
  historialConversacion.push({
    role: 'user',
    content: mensajeUsuario
  });

  console.log('ğŸ¤– Generando respuesta con GPT-4...');

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${CONFIG.openai_key}`
    },
    body: JSON.stringify({
      model: 'gpt-4o',
      messages: [
        {
          role: 'system',
          content: `Eres un agente telefÃ³nico de Enerlux, empresa de cambio de compaÃ±Ã­a elÃ©ctrica en EspaÃ±a.

Tu objetivo es convencer al cliente de cambiarse a Enerlux para ahorrar en su factura de luz.

REGLAS:
- SÃ© amable pero persuasivo
- Responde de forma BREVE (mÃ¡ximo 2 frases cortas, ideal para telefonÃ­a)
- Si el cliente estÃ¡ interesado, pide su nÃºmero de cuenta bancaria IBAN
- Si el cliente no estÃ¡ interesado, pregunta si conoce a alguien que pueda estarlo
- Si el cliente tiene preguntas, respÃ³ndelas claramente

INFORMACIÃ“N DE ENERLUX:
- Ahorro garantizado del 15-20% en factura mensual
- Sin permanencia
- Cambio gratis
- 100% energÃ­a renovable
- Precios congelados por 12 meses

Responde SIEMPRE en espaÃ±ol, de forma natural y conversacional.
IMPORTANTE: Tus respuestas deben ser CORTAS porque serÃ¡n convertidas a voz.`
        },
        ...historialConversacion.slice(-10)
      ],
      max_tokens: 100
    })
  });

  const data = await response.json();
  const respuesta = data.choices[0].message.content;

  historialConversacion.push({
    role: 'assistant',
    content: respuesta
  });

  console.log(`ğŸ¤– Respuesta: "${respuesta}"`);
  return respuesta;
}

/**
 * Convertir texto a voz con ElevenLabs
 */
async function textoAVoz(texto) {
  console.log('ğŸ”Š Convirtiendo a voz con ElevenLabs...');

  const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${CONFIG.elevenlabs_voice_id}`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'xi-api-key': CONFIG.elevenlabs_key
    },
    body: JSON.stringify({
      text: texto,
      model_id: 'eleven_multilingual_v2',
      voice_settings: {
        stability: 0.5,
        similarity_boost: 0.75,
        style: 0.5,
        use_speaker_boost: true
      }
    })
  });

  if (!response.ok) {
    console.log('âš ï¸ Error en ElevenLabs, usando fallback');
    return null;
  }

  const audioBuffer = await response.buffer();
  const outputFile = path.join(__dirname, 'temp', 'output.mp3');
  fs.writeFileSync(outputFile, audioBuffer);
  
  console.log(`âœ… Audio generado: ${outputFile}`);
  return outputFile;
}

// ========================================
// BUCLE PRINCIPAL DE CONVERSACIÃ“N
// ========================================

async function iniciarConversacion() {
  console.log('');
  console.log('ğŸ¯ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('ğŸ“ CONVERSACIÃ“N INICIADA');
  console.log('ğŸ¯ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('');
  
  conversacionActiva = true;
  historialConversacion = [];

  // Mensaje inicial
  const saludoInicial = "Hola, le llamo de Enerlux. Â¿PodrÃ­a hablar un momento sobre su factura de luz? Estamos ofreciendo un ahorro garantizado del 20 por ciento.";
  
  console.log(`ğŸ—£ï¸ IA: "${saludoInicial}"`);
  
  const audioSaludo = await textoAVoz(saludoInicial);
  if (audioSaludo) {
    await reproducirAudio(audioSaludo);
  }

  // Bucle de conversaciÃ³n
  while (conversacionActiva) {
    console.log('');
    console.log('â³ Escuchando al cliente...');
    
    // Grabar audio del cliente
    const audioFile = await grabarAudio(5000);
    
    // Transcribir
    const textoCliente = await transcribirAudio(audioFile);
    
    if (!textoCliente || textoCliente.trim() === '') {
      console.log('âš ï¸ No se detectÃ³ voz, preguntando si estÃ¡ ahÃ­...');
      const noVoz = await textoAVoz("Â¿Hola? Â¿Me escucha?");
      if (noVoz) await reproducirAudio(noVoz);
      continue;
    }

    console.log(`ğŸ‘¤ Cliente: "${textoCliente}"`);

    // Verificar si termina la conversaciÃ³n
    if (textoCliente.toLowerCase().includes('adiÃ³s') || 
        textoCliente.toLowerCase().includes('no me interesa') ||
        textoCliente.toLowerCase().includes('cuelgo')) {
      console.log('ğŸ“ El cliente quiere terminar...');
      const despedida = await textoAVoz("Entendido, gracias por su tiempo. Que tenga un buen dÃ­a.");
      if (despedida) await reproducirAudio(despedida);
      conversacionActiva = false;
      break;
    }

    // Generar respuesta
    const respuesta = await generarRespuesta(textoCliente);
    
    // Convertir a voz
    const audioRespuesta = await textoAVoz(respuesta);
    if (audioRespuesta) {
      await reproducirAudio(audioRespuesta);
    }
  }

  console.log('');
  console.log('âœ… ConversaciÃ³n finalizada');
}

// ========================================
// MODO INTERACTIVO (para pruebas)
// ========================================

async function modoInteractivo() {
  const readline = require('readline');
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout
  });

  console.log('');
  console.log('ğŸ® â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('ğŸ® MODO INTERACTIVO (pruebas sin audio)');
  console.log('ğŸ® Escribe lo que dirÃ­a el cliente');
  console.log('ğŸ® Escribe "salir" para terminar');
  console.log('ğŸ® â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('');

  // Saludo inicial
  const saludo = "Hola, le llamo de Enerlux. Â¿PodrÃ­a hablar un momento sobre su factura de luz?";
  console.log(`ğŸ—£ï¸ IA: "${saludo}"`);
  historialConversacion.push({ role: 'assistant', content: saludo });

  const preguntar = () => {
    rl.question('ğŸ‘¤ Cliente: ', async (input) => {
      if (input.toLowerCase() === 'salir') {
        console.log('ğŸ‘‹ Â¡Hasta luego!');
        rl.close();
        return;
      }

      const respuesta = await generarRespuesta(input);
      console.log(`ğŸ—£ï¸ IA: "${respuesta}"`);

      // Generar audio tambiÃ©n
      const audio = await textoAVoz(respuesta);
      if (audio) {
        console.log(`ğŸ”Š Audio guardado en: ${audio}`);
      }

      preguntar();
    });
  };

  preguntar();
}

// ========================================
// INICIAR
// ========================================

// Detectar modo
const args = process.argv.slice(2);
if (args.includes('--interactivo') || args.includes('-i')) {
  modoInteractivo();
} else if (args.includes('--llamar') || args.includes('-l')) {
  iniciarConversacion();
} else {
  console.log('ğŸ“ USO:');
  console.log('');
  console.log('  node server-local.js --interactivo  â†’ Prueba escribiendo');
  console.log('  node server-local.js --llamar       â†’ Con audio real (VB-CABLE)');
  console.log('');
  console.log('âš¡ Iniciando modo interactivo por defecto...');
  console.log('');
  modoInteractivo();
}